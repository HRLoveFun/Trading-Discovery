{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "# import os\n",
    "# from fredapi import Fred\n",
    "\n",
    "from marketobserve import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9445.000000</td>\n",
       "      <td>9445.000000</td>\n",
       "      <td>9445.000000</td>\n",
       "      <td>9445.000000</td>\n",
       "      <td>9445.000000</td>\n",
       "      <td>9.445000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15731.337912</td>\n",
       "      <td>15836.078826</td>\n",
       "      <td>15608.299126</td>\n",
       "      <td>15725.260673</td>\n",
       "      <td>15725.260673</td>\n",
       "      <td>1.016739e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7934.279690</td>\n",
       "      <td>7977.676224</td>\n",
       "      <td>7875.395237</td>\n",
       "      <td>7926.633924</td>\n",
       "      <td>7926.633924</td>\n",
       "      <td>1.157914e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1950.500000</td>\n",
       "      <td>1950.500000</td>\n",
       "      <td>1894.900024</td>\n",
       "      <td>1894.900024</td>\n",
       "      <td>1894.900024</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9633.429688</td>\n",
       "      <td>9696.700195</td>\n",
       "      <td>9554.309570</td>\n",
       "      <td>9632.500000</td>\n",
       "      <td>9632.500000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15747.559570</td>\n",
       "      <td>15861.169922</td>\n",
       "      <td>15613.200195</td>\n",
       "      <td>15742.299805</td>\n",
       "      <td>15742.299805</td>\n",
       "      <td>4.226760e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22477.599609</td>\n",
       "      <td>22588.689453</td>\n",
       "      <td>22300.089844</td>\n",
       "      <td>22455.839844</td>\n",
       "      <td>22455.839844</td>\n",
       "      <td>1.788490e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33335.480469</td>\n",
       "      <td>33484.078125</td>\n",
       "      <td>32897.039062</td>\n",
       "      <td>33154.121094</td>\n",
       "      <td>33154.121094</td>\n",
       "      <td>1.268650e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price          Open          High           Low         Close     Adj Close  \\\n",
       "count   9445.000000   9445.000000   9445.000000   9445.000000   9445.000000   \n",
       "mean   15731.337912  15836.078826  15608.299126  15725.260673  15725.260673   \n",
       "std     7934.279690   7977.676224   7875.395237   7926.633924   7926.633924   \n",
       "min     1950.500000   1950.500000   1894.900024   1894.900024   1894.900024   \n",
       "25%     9633.429688   9696.700195   9554.309570   9632.500000   9632.500000   \n",
       "50%    15747.559570  15861.169922  15613.200195  15742.299805  15742.299805   \n",
       "75%    22477.599609  22588.689453  22300.089844  22455.839844  22455.839844   \n",
       "max    33335.480469  33484.078125  32897.039062  33154.121094  33154.121094   \n",
       "\n",
       "Price        Volume  \n",
       "count  9.445000e+03  \n",
       "mean   1.016739e+09  \n",
       "std    1.157914e+09  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    4.226760e+08  \n",
       "75%    1.788490e+09  \n",
       "max    1.268650e+10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage:\n",
    "start = dt.date(1900, 1, 1)\n",
    "end = dt.date(2026, 1, 1)\n",
    "ticker = \"^HSI\"\n",
    "data = yf_download(ticker, start, end)\n",
    "# data.index = data.index.strftime('%Y-%m')\n",
    "# data.to_excel(f\"{ticker}.xlsx\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_sources(df, periods, all_period_start, frequency):\n",
    "    \"\"\"\n",
    "    创建不同时间周期的数据来源\n",
    "    \"\"\"\n",
    "    current_date = pd.Timestamp.now()\n",
    "\n",
    "    # 根据 frequency 筛选数据到本周/本月/本季度的第一天\n",
    "    if frequency == 'ME':\n",
    "        end_date = current_date.replace(day=1)\n",
    "    elif frequency == 'W':\n",
    "        end_date = current_date - pd.DateOffset(days=current_date.weekday())\n",
    "    elif frequency == 'QE':\n",
    "        end_date = current_date - pd.tseries.offsets.QuarterBegin()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid frequency value. Allowed values are 'ME', 'W', 'QE'.\")\n",
    "\n",
    "    df = df[df.index < end_date]\n",
    "    last_date = df.index[-1]\n",
    "\n",
    "    if all_period_start is None:\n",
    "        all_period_start = \"2010-01-01\"\n",
    "\n",
    "    data_sources = {}\n",
    "    for period in periods:\n",
    "        if isinstance(period, int):\n",
    "            if frequency in ['ME', 'W']:\n",
    "                start_date = last_date - pd.DateOffset(months=period - 1)\n",
    "            elif frequency == 'QE':\n",
    "                start_date = last_date - pd.DateOffset(quarters=period - 1)\n",
    "            col_name = f\"{start_date.strftime('%y%b')}-{last_date.strftime('%y%b')}\"\n",
    "            data_sources[col_name] = df.loc[df.index >= start_date]\n",
    "        elif period == \"ALL\":\n",
    "            col_name = f\"{pd.to_datetime(all_period_start).strftime('%y%b')}-{last_date.strftime('%y%b')}\"\n",
    "            data_sources[col_name] = df.loc[df.index >= all_period_start]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid period value\")\n",
    "\n",
    "    return data_sources\n",
    "\n",
    "\n",
    "def refrequency(df, frequency: str):\n",
    "    \"\"\"\n",
    "    对数据进行重采样\n",
    "    \"\"\"\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"DataFrame index must be a DatetimeIndex\")\n",
    "    if not {'Open', 'High', 'Low', 'Close'}.issubset(df.columns):\n",
    "        raise ValueError(\"DataFrame must contain OHLC columns\")\n",
    "\n",
    "    try:\n",
    "        refrequency_df = df.resample(frequency).agg({\n",
    "            'Open': 'first',\n",
    "            'High': 'max',\n",
    "            'Low': 'min',\n",
    "            'Close': 'last',\n",
    "            'Adj Close': 'last',\n",
    "            'Volume': 'sum'\n",
    "        }).dropna()\n",
    "\n",
    "    except KeyError as e:\n",
    "        import logging\n",
    "        logging.error(f\"Missing column {e} in DataFrame\")\n",
    "        raise ValueError(f\"Error processing data: Missing column {e}\")\n",
    "    except Exception as e:\n",
    "        import logging\n",
    "        logging.error(f\"Unexpected error: {str(e)}\")\n",
    "        raise ValueError(f\"Error processing data: {str(e)}\")\n",
    "\n",
    "\n",
    "    return refrequency_df\n",
    "\n",
    "\n",
    "def oscillation(df):\n",
    "    \"\"\"\n",
    "    计算震荡指标\n",
    "    \"\"\"\n",
    "    data = df[['Open', 'High', 'Low', 'Close']].copy()\n",
    "    data['LastClose'] = data[\"Close\"].shift(1)\n",
    "    data[\"Oscillation\"] = data[\"High\"] - data[\"Low\"]\n",
    "    data[\"OscillationPct\"] = data[\"Oscillation\"] / data['LastClose'] * 100\n",
    "    data = data.dropna()\n",
    "    return data\n",
    "\n",
    "\n",
    "def tail_stats(df, feature, frequency, periods: list = [12, 36, 60, \"ALL\"], all_period_start: str = None, interpolation: str = \"linear\"):\n",
    "    \"\"\"\n",
    "    计算不同时间周期的统计指标\n",
    "    \"\"\"\n",
    "    if not isinstance(periods, list):\n",
    "        raise TypeError(\"periods must be a list\")\n",
    "    if not all(isinstance(p, (int, str)) for p in periods):\n",
    "        raise ValueError(\"periods must contain integers or strings\")\n",
    "\n",
    "    data_sources = create_data_sources(df, periods, all_period_start, frequency)\n",
    "\n",
    "    stats_index = pd.Index([\"mean\", \"std\", \"skew\", \"kurt\", \"max\", \"99th\", \"95th\", \"90th\"])\n",
    "    stats_df = pd.DataFrame(index=stats_index)\n",
    "\n",
    "    for period_name, data in data_sources.items():\n",
    "        stats_df[period_name] = [\n",
    "            data[feature].mean(),\n",
    "            data[feature].std(),\n",
    "            data[feature].skew(),\n",
    "            data[feature].kurtosis(),\n",
    "            data[feature].max(),\n",
    "            data[feature].quantile(0.99, interpolation=interpolation),\n",
    "            data[feature].quantile(0.95, interpolation=interpolation),\n",
    "            data[feature].quantile(0.90, interpolation=interpolation)\n",
    "        ]\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "\n",
    "def tail_plot(df, feature, frequency, periods: list = [12, 36, 60, \"ALL\"], all_period_start: str = None, interpolation: str = \"linear\"):\n",
    "    \"\"\"\n",
    "    绘制不同时间周期的特征值分布\n",
    "    \"\"\"\n",
    "    data_sources = create_data_sources(df, periods, all_period_start, frequency)\n",
    "\n",
    "    if frequency == \"ME\":\n",
    "        bin_range = list(range(0, 35, 5))\n",
    "    elif frequency == \"W\":\n",
    "        bin_range = list(range(0, 18, 3))\n",
    "\n",
    "\n",
    "    for period_name, data in data_sources.items():\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.set_style(\"darkgrid\")\n",
    "        n, bins, patches = plt.hist(data[feature], bins=bin_range, alpha=0.5, color='skyblue', density=True, cumulative=True)\n",
    "\n",
    "        n_diff = np.insert(np.diff(n), 0, n[0])\n",
    "        for rect, h_diff, h in zip(patches, n_diff, n):\n",
    "            height = rect.get_height()\n",
    "            plt.text(rect.get_x() + rect.get_width() / 2, height, f'{h_diff * 100:.0f}%/{h * 100:.0f}%', ha='center', va='bottom', size=12)\n",
    "\n",
    "        percentiles = [data[feature].quantile(p, interpolation=interpolation) for p in [0.90, 0.95, 0.99]]\n",
    "        for p, val in zip([90, 95, 99], percentiles):\n",
    "            plt.axvline(val, color='red', linestyle=':', alpha=0.3, label=f'{p}th: {val:.1f}%')\n",
    "\n",
    "        last_three = data[feature].iloc[-3:]\n",
    "        last_three_dates = last_three.index.strftime('%Y%b')\n",
    "        for val, date, grayscale in zip(last_three, last_three_dates, np.arange(0.7, 0, -0.3)):\n",
    "            plt.scatter(val, 0, color=str(grayscale), s=100, zorder=5, label=f'{date}: {val:.1f}%')\n",
    "\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.title(f\"Distribution of {feature} - {period_name}\")\n",
    "        plt.xlabel(f\"{feature} (%)\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def calculate_projections(data, feature, percentile, interpolation, bias_weight):\n",
    "    data[\"ProjectHigh\"] = data[\"LastClose\"] + data[\"LastClose\"] * data[feature].quantile(percentile, interpolation=interpolation) / 100 * bias_weight\n",
    "    data[\"ProjectLow\"] = data[\"LastClose\"] - data[\"LastClose\"] * data[feature].quantile(percentile, interpolation=interpolation) / 100 * (1 - bias_weight)\n",
    "    data[\"ActualClosingStatus\"] = np.where(data[\"Close\"] > data[\"ProjectHigh\"], 1, \n",
    "                                       np.where(data[\"Close\"] < data[\"ProjectLow\"], -1, 0))\n",
    "    realized_bias = ((data[\"ActualClosingStatus\"] == 1).sum() - ((data[\"ActualClosingStatus\"] == -1).sum())) / len(data)\n",
    "    \n",
    "    return realized_bias\n",
    "\n",
    "def volatility_projection(df, feature, frequency: str = 'ME', percentile: float = 0.90, prefer_bias: float = None, periods: list = [12, 36, 60, \"ALL\"], all_period_start: str = None, interpolation: str = \"linear\"):\n",
    "    \"\"\"\n",
    "    计算不同时间周期的波动率预测\n",
    "    \"\"\"\n",
    "    if not isinstance(periods, list):\n",
    "        raise TypeError(\"periods must be a list\")\n",
    "    if not all(isinstance(p, (int, str)) for p in periods):\n",
    "        raise ValueError(\"periods must contain integers or strings\")\n",
    "\n",
    "    if feature == \"OscillationPct\":\n",
    "        refrequency_data = refrequency(df, frequency=frequency)\n",
    "        refrequency_feature = oscillation(refrequency_data)\n",
    "\n",
    "        data_sources = create_data_sources(refrequency_feature, periods, all_period_start, frequency)\n",
    "\n",
    "        volatility_projection_index = pd.Index(\n",
    "            [\n",
    "                f\"Last: {refrequency_feature.index[-2].strftime('%y%b%d')}\", \n",
    "                f\"{percentile}th {feature}\", \n",
    "                \"RealizedBias%\",  \n",
    "                \"ProjectedHighWeight%\", \n",
    "                \"ProjHigh\", \n",
    "                \"ProjLow\", \n",
    "                f\"Today: {df.index[-1].strftime('%y%b%d')}\"\n",
    "                ]\n",
    "            )\n",
    "        volatility_projection_df = pd.DataFrame(index=volatility_projection_index)\n",
    "\n",
    "        for period_name, data in data_sources.items():\n",
    "            period_end_close = data[\"Close\"].iloc[-1]\n",
    "            assumed_volatility = data[feature].quantile(percentile, interpolation=interpolation)\n",
    "\n",
    "            if prefer_bias is not None:\n",
    "                # 寻找最佳 bias_weight 的逻辑\n",
    "                proj_high_weights = np.linspace(0.1, 0.9, 90)  # 在 0 到 1 之间生成 100 个等间距的 bias_weight 值\n",
    "                min_error = float('inf')\n",
    "                best_proj_high_weight = 0\n",
    "                for proj_high_weight in proj_high_weights:\n",
    "                    realized_bias = calculate_projections(data.copy(), feature, percentile, interpolation, proj_high_weight)\n",
    "                    error = abs(realized_bias - prefer_bias)\n",
    "                    if error < min_error:\n",
    "                        min_error = error\n",
    "                        best_proj_high_weight = proj_high_weight\n",
    "                proj_high_weight = best_proj_high_weight            \n",
    "            \n",
    "            else:\n",
    "                proj_high_weight = 0.5\n",
    "\n",
    "            realized_bias = calculate_projections(data, feature, percentile, interpolation, proj_high_weight)\n",
    "\n",
    "            proj_high = period_end_close + period_end_close * assumed_volatility / 100 * proj_high_weight\n",
    "            proj_low = period_end_close - period_end_close * assumed_volatility / 100 * (1 - proj_high_weight)\n",
    "            \n",
    "            last_close = df[\"Close\"].iloc[-1]\n",
    "\n",
    "            volatility_projection_df[period_name] = [\n",
    "                period_end_close,\n",
    "                assumed_volatility,\n",
    "                realized_bias*100,\n",
    "                proj_high_weight*100,\n",
    "                proj_high,\n",
    "                proj_low,\n",
    "                last_close\n",
    "            ]\n",
    "        return volatility_projection_df\n",
    "    else:\n",
    "        raise ValueError(\"Invalid feature value\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tail_table(df, feature, frequency, periods: list = [12, 36, 60, \"ALL\"], all_period_start: str = None, interpolation: str = \"linear\"):\n",
    "    \"\"\"\n",
    "    **To Modify Ouput Table Information** 按每个时间段计算表格，输出每个时间段及其对应的表格，最后将结果存储在字典中返回\n",
    "    \"\"\"\n",
    "    data_sources = create_data_sources(df, periods, all_period_start, frequency)\n",
    "\n",
    "    if frequency == \"ME\":\n",
    "        bin_range = list(range(0, 35, 5))\n",
    "    elif frequency == \"W\":\n",
    "        bin_range = list(range(0, 18, 3))\n",
    "\n",
    "    result_dict = {}\n",
    "    for period_name, data in data_sources.items():\n",
    "        # 计算直方图的累积密度\n",
    "        n, bins = np.histogram(data[feature], bins=bin_range, density=True)\n",
    "        cumulative_n = np.cumsum(n * np.diff(bins))\n",
    "        n_diff = np.insert(np.diff(cumulative_n), 0, cumulative_n[0])\n",
    "\n",
    "        # 计算百分位数\n",
    "        percentiles = [data[feature].quantile(p, interpolation=interpolation) for p in [0.90, 0.95, 0.99]]\n",
    "\n",
    "        # 获取最后三个数据点\n",
    "        last_three = data[feature].iloc[-3:]\n",
    "        last_three_dates = last_three.index.strftime('%Y%b')\n",
    "\n",
    "        table_data = []\n",
    "        for i in range(len(bins) - 1):\n",
    "            bin_info = {\n",
    "                \"Period\": period_name,\n",
    "                \"Bin Start\": bins[i],\n",
    "                \"Bin End\": bins[i + 1],\n",
    "                \"Diff Percentage\": f'{n_diff[i] * 100:.0f}%',\n",
    "                \"Cumulative Percentage\": f'{cumulative_n[i] * 100:.0f}%',\n",
    "                \"90th Percentile\": percentiles[0],\n",
    "                \"95th Percentile\": percentiles[1],\n",
    "                \"99th Percentile\": percentiles[2],\n",
    "            }\n",
    "            for j, (date, val) in enumerate(zip(last_three_dates, last_three)):\n",
    "                bin_info[f\"Last {3 - j} Date\"] = date\n",
    "                bin_info[f\"Last {3 - j} Value\"] = val\n",
    "            table_data.append(bin_info)\n",
    "\n",
    "        table = pd.DataFrame(table_data)\n",
    "        print(period_name, table)\n",
    "        result_dict[period_name] = table\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def frequency_gap_stats(df, feature, frequency, periods: list = [12, 36, 60, \"ALL\"], all_period_start: str = None, interpolation: str = \"linear\"):\n",
    "    \"\"\"\n",
    "    计算不同时间周期的频率缺口统计\n",
    "    Given df, feature, and frequency,\n",
    "        for each period in frequency,\n",
    "            compute the gap_return = percentage change of first date open over last period close\n",
    "            compute statistics of gap_return\n",
    "            compute frequency_return = percentage change of last date close over last period close\n",
    "            set days_of_period = len(df[rows only in the period])\n",
    "            compare distribution of (gap_return+1)**days_of_period-1 with frequency_return distribution\n",
    "        return distribution table of gap_return \n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency = 'ME'\n",
    "# monthly_data = refrequency(data, frequency=frequency)\n",
    "# monthly_oscill = oscillation(monthly_data)\n",
    "# monthly_tail_stats_result =tail_stats(monthly_oscill,\"OscillationPct\",frequency=frequency)\n",
    "# print(monthly_tail_stats_result,\"\\n\")\n",
    "\n",
    "# round_digit = 1\n",
    "# tail_plot(monthly_oscill,\"OscillationPct\",frequency=frequency)\n",
    "# volatility_proj_pbn = volatility_projection(data,\"OscillationPct\",frequency=frequency,prefer_bias=None).round(round_digit)\n",
    "# print(volatility_proj_pbn,\"\\n\")\n",
    "# volatility_proj_pb0 = volatility_projection(data,\"OscillationPct\",frequency=frequency,prefer_bias=0).round(round_digit)\n",
    "# print(volatility_proj_pb0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      24May-25Apr  22May-25Apr  20May-25Apr  10Jan-25Apr\n",
      "mean     4.719653     4.750659     4.487516     3.667798\n",
      "std      2.579451     2.200721     2.098890     1.895296\n",
      "skew     1.925695     1.915009     2.228378     2.034881\n",
      "kurt     4.548465     5.038169     8.069789     7.257269\n",
      "max     13.859898    13.859898    16.593874    16.593874\n",
      "99th    13.652987    13.543815    13.533469    10.378523\n",
      "95th     9.388461     8.982476     7.598381     6.901116\n",
      "90th     6.992733     7.050944     6.606538     5.989418 \n",
      "\n",
      "                      24May-25Apr  22May-25Apr  20May-25Apr  10Jan-25Apr\n",
      "25Apr06                   22849.8      22849.8      22849.8      22849.8\n",
      "0.9th OscillationPct          7.0          7.1          6.6          6.0\n",
      "RealizedBias%                 4.2          2.0         -2.7         -1.0\n",
      "ProjectedHighWeight%         50.0         50.0         50.0         50.0\n",
      "ProjHigh                  23648.7      23655.4      23604.6      23534.1\n",
      "ProjLow                   22050.9      22044.2      22095.0      22165.5\n",
      "25Apr08                   20157.5      20157.5      20157.5      20157.5 \n",
      "\n",
      "                      24May-25Apr  22May-25Apr  20May-25Apr  10Jan-25Apr\n",
      "25Apr06                   22849.8      22849.8      22849.8      22849.8\n",
      "0.9th OscillationPct          7.0          7.1          6.6          6.0\n",
      "RealizedBias%                 0.0          0.0          0.4         -0.4\n",
      "ProjectedHighWeight%         56.7         52.2         46.9         49.6\n",
      "ProjHigh                  23756.4      23691.6      23557.1      23527.9\n",
      "ProjLow                   22158.6      22080.5      22047.5      22159.4\n",
      "25Apr08                   20157.5      20157.5      20157.5      20157.5\n"
     ]
    }
   ],
   "source": [
    "frequency = 'W'\n",
    "refrequency_data = refrequency(data, frequency=frequency)\n",
    "oscill = oscillation(refrequency_data)\n",
    "tail_stats_result =tail_stats(oscill,\"OscillationPct\",frequency=frequency)\n",
    "print(tail_stats_result,\"\\n\")\n",
    "\n",
    "round_digit = 1\n",
    "# tail_plot(oscill,\"OscillationPct\",frequency=frequency)\n",
    "# tail_hist = tail_table(oscill,\"OscillationPct\",frequency=frequency)\n",
    "# print(tail_hist,\"\\n\")\n",
    "volatility_proj_pbn = volatility_projection(data,\"OscillationPct\",frequency=frequency,prefer_bias=None).round(round_digit)\n",
    "print(volatility_proj_pbn,\"\\n\")\n",
    "volatility_proj_pb0 = volatility_projection(data,\"OscillationPct\",frequency=frequency,prefer_bias=0).round(round_digit)\n",
    "print(volatility_proj_pb0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "# mo.ChangeDistPlot(data, time_windows=['1Y', ('20240101', '20250401'), '100Y'], frequencies = ['W', 'M'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
